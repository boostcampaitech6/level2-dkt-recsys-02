{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoost Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from catboost import CatBoostRegressor as cbt\n",
    "from catboost import Pool\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>assessmentItemID</th>\n",
       "      <th>testId</th>\n",
       "      <th>answerCode</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>KnowledgeTag</th>\n",
       "      <th>Dffclt</th>\n",
       "      <th>Dscrmn</th>\n",
       "      <th>Gussng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A060001001</td>\n",
       "      <td>A060000001</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-03-24 00:17:11</td>\n",
       "      <td>7224</td>\n",
       "      <td>-2.017182</td>\n",
       "      <td>20.079513</td>\n",
       "      <td>0.052178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>A060001002</td>\n",
       "      <td>A060000001</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-03-24 00:17:14</td>\n",
       "      <td>7225</td>\n",
       "      <td>-1.723821</td>\n",
       "      <td>4.616495</td>\n",
       "      <td>0.056888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>A060001003</td>\n",
       "      <td>A060000001</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-03-24 00:17:22</td>\n",
       "      <td>7225</td>\n",
       "      <td>-0.167255</td>\n",
       "      <td>18.583456</td>\n",
       "      <td>0.754422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>A060001004</td>\n",
       "      <td>A060000001</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-03-24 00:17:29</td>\n",
       "      <td>7225</td>\n",
       "      <td>0.496282</td>\n",
       "      <td>39.877030</td>\n",
       "      <td>0.946875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>A060001005</td>\n",
       "      <td>A060000001</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-03-24 00:17:36</td>\n",
       "      <td>7225</td>\n",
       "      <td>-1.335100</td>\n",
       "      <td>6.965071</td>\n",
       "      <td>0.237969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2266581</th>\n",
       "      <td>7441</td>\n",
       "      <td>A030071005</td>\n",
       "      <td>A030000071</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-06-05 06:50:21</td>\n",
       "      <td>438</td>\n",
       "      <td>0.767458</td>\n",
       "      <td>0.882364</td>\n",
       "      <td>0.123318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2266582</th>\n",
       "      <td>7441</td>\n",
       "      <td>A040165001</td>\n",
       "      <td>A040000165</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-08-21 01:06:39</td>\n",
       "      <td>8836</td>\n",
       "      <td>-0.277564</td>\n",
       "      <td>5.384278</td>\n",
       "      <td>0.099105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2266583</th>\n",
       "      <td>7441</td>\n",
       "      <td>A040165002</td>\n",
       "      <td>A040000165</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-08-21 01:06:50</td>\n",
       "      <td>8836</td>\n",
       "      <td>-0.267161</td>\n",
       "      <td>10.263590</td>\n",
       "      <td>0.035658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2266584</th>\n",
       "      <td>7441</td>\n",
       "      <td>A040165003</td>\n",
       "      <td>A040000165</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-08-21 01:07:36</td>\n",
       "      <td>8836</td>\n",
       "      <td>-0.229779</td>\n",
       "      <td>1.516802</td>\n",
       "      <td>0.513883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2266585</th>\n",
       "      <td>7441</td>\n",
       "      <td>A040165004</td>\n",
       "      <td>A040000165</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-08-21 01:08:49</td>\n",
       "      <td>8836</td>\n",
       "      <td>-0.113676</td>\n",
       "      <td>1.901030</td>\n",
       "      <td>0.013027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2266586 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         userID assessmentItemID      testId  answerCode            Timestamp  \\\n",
       "0             0       A060001001  A060000001           1  2020-03-24 00:17:11   \n",
       "1             0       A060001002  A060000001           1  2020-03-24 00:17:14   \n",
       "2             0       A060001003  A060000001           1  2020-03-24 00:17:22   \n",
       "3             0       A060001004  A060000001           1  2020-03-24 00:17:29   \n",
       "4             0       A060001005  A060000001           1  2020-03-24 00:17:36   \n",
       "...         ...              ...         ...         ...                  ...   \n",
       "2266581    7441       A030071005  A030000071           0  2020-06-05 06:50:21   \n",
       "2266582    7441       A040165001  A040000165           1  2020-08-21 01:06:39   \n",
       "2266583    7441       A040165002  A040000165           1  2020-08-21 01:06:50   \n",
       "2266584    7441       A040165003  A040000165           1  2020-08-21 01:07:36   \n",
       "2266585    7441       A040165004  A040000165           1  2020-08-21 01:08:49   \n",
       "\n",
       "         KnowledgeTag    Dffclt     Dscrmn    Gussng  \n",
       "0                7224 -2.017182  20.079513  0.052178  \n",
       "1                7225 -1.723821   4.616495  0.056888  \n",
       "2                7225 -0.167255  18.583456  0.754422  \n",
       "3                7225  0.496282  39.877030  0.946875  \n",
       "4                7225 -1.335100   6.965071  0.237969  \n",
       "...               ...       ...        ...       ...  \n",
       "2266581           438  0.767458   0.882364  0.123318  \n",
       "2266582          8836 -0.277564   5.384278  0.099105  \n",
       "2266583          8836 -0.267161  10.263590  0.035658  \n",
       "2266584          8836 -0.229779   1.516802  0.513883  \n",
       "2266585          8836 -0.113676   1.901030  0.013027  \n",
       "\n",
       "[2266586 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = '/data/ephemeral/level2-dkt-recsys-02/data/' # 경로는 상황에 맞춰서 수정해주세요!\n",
    "csv_file_path = os.path.join(data_dir, 'train_data_3PL+level.csv')\n",
    "df = pd.read_csv(csv_file_path)\n",
    "df = df.drop(['user_level'], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "\n",
    "    # 유저별로 정렬\n",
    "    df.sort_values(by=['userID', 'Timestamp'], inplace=True)\n",
    "    \n",
    "    # 데이터 타입 변경\n",
    "    dtype = {\n",
    "        'userID': 'int16',\n",
    "        'answerCode': 'int8',\n",
    "        'KnowledgeTag': 'int16'\n",
    "    }\n",
    "    df = df.astype(dtype)\n",
    "    \n",
    "    # 'Timestamp' 열을 날짜/시간 형식으로 파싱\n",
    "    df['Timestamp'] = pd.to_datetime(df['Timestamp'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    # testTag 추가\n",
    "    df['testTag'] = df['testId'].apply(lambda x: x[2]).astype('int16')\n",
    "\n",
    "    # 유저별로 정답 누적 횟수 계산, 결측치 0\n",
    "    df['user_correct_answer'] = df.groupby('userID')['answerCode'].transform(lambda x: x.cumsum().shift(1))\n",
    "    df['user_correct_answer'].fillna(0, inplace=True)\n",
    "    \n",
    "    # 유저별로 제출 누적 횟수 계산\n",
    "    df['user_total_answer'] = df.groupby('userID')['answerCode'].cumcount() \n",
    "    \n",
    "    # 유저별로 누적 정답률 계산, 결측치 0.75\n",
    "    df['user_acc'] = df['user_correct_answer'] / df['user_total_answer']\n",
    "    df['user_acc'].fillna(0.75, inplace=True)\n",
    "\n",
    "    # userID별 정답률 추가\n",
    "    df['user_sum'] = df.groupby('userID')['answerCode'].transform('sum')\n",
    "    df['user_mean'] = df.groupby('userID')['answerCode'].transform('mean')\n",
    "    \n",
    "    # assessmentItemID별 정답률 추가\n",
    "    df['assessment_sum'] = df.groupby('assessmentItemID')['answerCode'].transform('sum')\n",
    "    df['assessment_mean'] = df.groupby('assessmentItemID')['answerCode'].transform('mean')\n",
    "    \n",
    "    # testId별 정답률 추가\n",
    "    df['test_sum'] = df.groupby('testId')['answerCode'].transform('sum')\n",
    "    df['test_mean'] = df.groupby('testId')['answerCode'].transform('mean')\n",
    "    \n",
    "    # KnowledgeTag별 정답률 추가\n",
    "    df['knowledgeTag_sum'] = df.groupby('KnowledgeTag')['answerCode'].transform('sum')\n",
    "    df['knowledgeTag_mean'] = df.groupby('KnowledgeTag')['answerCode'].transform('mean')\n",
    "    \n",
    "    # testTag별 정답률 추가\n",
    "    df['testTag_sum'] = df.groupby('testTag')['answerCode'].transform('sum')\n",
    "    df['testTag_mean'] = df.groupby('testTag')['answerCode'].transform('mean')\n",
    "\n",
    "    # 상대적 정답률\n",
    "    df['relative_answer_assessment'] = df['answerCode'] - df.groupby('assessmentItemID')['answerCode'].transform('mean')\n",
    "    \n",
    "    # 유저별 상대적 정답률 평균 - 학습 수준 레벨\n",
    "    df['relative_answer_mean'] = df.groupby('userID')['relative_answer_assessment'].transform('mean')\n",
    "\n",
    "    # 유저가 문항을 푼 시간\n",
    "    df['time_to_solve'] = df.groupby(['userID', 'testId'])['Timestamp'].diff().dt.total_seconds().shift(-1)\n",
    "    \n",
    "    # 결측치 이전 행의 값으로 채움\n",
    "    df['time_to_solve'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "    # 유저별 문항 시간 평균\n",
    "    #df['time_to_solve_mean'] = df.groupby('userID')['time_to_solve'].transform('mean')\n",
    "    df['time_to_solve_mean'] = df.groupby(['userID', 'testId'])['time_to_solve'].transform('mean')\n",
    "\n",
    "    # clip(0, 255)는 메모리를 위해 uint8 데이터 타입을 쓰기 위함\n",
    "    df['prior_assessment_frequency'] = df.groupby(['userID', 'assessmentItemID']).cumcount().clip(0, 255)\n",
    "\n",
    "    # 각 태그별로 이전에 몇번 풀었는지\n",
    "    df['prior_KnowledgeTag_frequency'] = df.groupby(['userID', 'KnowledgeTag']).cumcount()\n",
    "    \n",
    "    # 시험지 태그별 학년별 몇번 풀었는지\n",
    "    df['prior_testTag_frequency'] = df.groupby(['userID', 'testTag']).cumcount()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_369617/4246852483.py:61: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df['time_to_solve'].fillna(method='ffill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df = feature_engineering(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test 데이터 셋 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "def custom_train_test_split(df, ratio=0.7, split=True):\n",
    "\n",
    "    users = list(zip(df['userID'].value_counts().index, df['userID'].value_counts()))\n",
    "    random.shuffle(users)\n",
    "\n",
    "    max_train_data_len = ratio*len(df)\n",
    "    sum_of_train_data = 0\n",
    "    user_ids =[]\n",
    "\n",
    "    for user_id, count in users:\n",
    "        sum_of_train_data += count\n",
    "        if max_train_data_len < sum_of_train_data:\n",
    "            break\n",
    "        user_ids.append(user_id)\n",
    "\n",
    "\n",
    "    train = df[df['userID'].isin(user_ids)]\n",
    "    test = df[df['userID'].isin(user_ids) == False]\n",
    "\n",
    "    #test데이터셋은 각 유저의 마지막 interaction만 추출\n",
    "    test = test[test['userID'] != test['userID'].shift(-1)]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['userID', 'assessmentItemID', 'testId', 'answerCode', 'Timestamp',\n",
       "       'KnowledgeTag', 'Dffclt', 'Dscrmn', 'Gussng', 'testTag',\n",
       "       'user_correct_answer', 'user_total_answer', 'user_acc', 'user_sum',\n",
       "       'user_mean', 'assessment_sum', 'assessment_mean', 'test_sum',\n",
       "       'test_mean', 'knowledgeTag_sum', 'knowledgeTag_mean', 'testTag_sum',\n",
       "       'testTag_mean', 'relative_answer_assessment', 'relative_answer_mean',\n",
       "       'time_to_solve', 'time_to_solve_mean', 'prior_assessment_frequency',\n",
       "       'prior_KnowledgeTag_frequency', 'prior_testTag_frequency'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유저별 분리\n",
    "train, test = custom_train_test_split(df)\n",
    "\n",
    "# 사용할 Feature 설정\n",
    "FEATS = [\n",
    "#  'userID',\n",
    "#  'assessmentItemID',\n",
    "#  'testId',\n",
    "#  'answerCode',\n",
    "#  'Timestamp',\n",
    " 'KnowledgeTag',\n",
    " 'Dffclt',\n",
    " 'Dscrmn',\n",
    " 'Gussng',\n",
    " 'testTag',\n",
    " 'user_correct_answer',\n",
    " 'user_total_answer',\n",
    " 'user_acc',\n",
    "#  'user_sum',\n",
    " 'user_mean',\n",
    "#  'assessment_sum',\n",
    "#  'assessment_mean',\n",
    "#  'test_sum',\n",
    "#  'test_mean',\n",
    "#  'knowledgeTag_sum',\n",
    "#  'knowledgeTag_mean',\n",
    "#  'testTag_sum',\n",
    "#  'testTag_mean',\n",
    "#  'relative_answer_assessment',\n",
    " 'relative_answer_mean',\n",
    " 'time_to_solve',\n",
    " 'time_to_solve_mean',\n",
    "#  'prior_assessment_frequency',\n",
    "#  'prior_KnowledgeTag_frequency',\n",
    " 'prior_testTag_frequency'\n",
    " ]\n",
    "# X, y 값 분리\n",
    "y_train = train['answerCode']\n",
    "train = train.drop(['answerCode'], axis=1)\n",
    "\n",
    "y_test = test['answerCode']\n",
    "test = test.drop(['answerCode'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = Pool(data=train[FEATS], label=y_train, cat_features=[0, 4])\n",
    "data_test = Pool(data=test[FEATS], label=y_test, cat_features=[0, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련 및 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.7561921\tbest: 0.7561921 (0)\ttotal: 515ms\tremaining: 4m 16s\n",
      "50:\ttest: 0.7840049\tbest: 0.7840049 (50)\ttotal: 19.6s\tremaining: 2m 52s\n",
      "100:\ttest: 0.7912642\tbest: 0.7912642 (100)\ttotal: 37.3s\tremaining: 2m 27s\n",
      "150:\ttest: 0.7946320\tbest: 0.7946320 (150)\ttotal: 55.5s\tremaining: 2m 8s\n",
      "200:\ttest: 0.7964680\tbest: 0.7964680 (200)\ttotal: 1m 13s\tremaining: 1m 48s\n",
      "250:\ttest: 0.7977495\tbest: 0.7977495 (250)\ttotal: 1m 31s\tremaining: 1m 30s\n",
      "300:\ttest: 0.7988605\tbest: 0.7988605 (300)\ttotal: 1m 49s\tremaining: 1m 12s\n",
      "350:\ttest: 0.7994280\tbest: 0.7994329 (348)\ttotal: 2m 7s\tremaining: 54s\n",
      "400:\ttest: 0.8000632\tbest: 0.8000632 (400)\ttotal: 2m 25s\tremaining: 36s\n",
      "450:\ttest: 0.8005798\tbest: 0.8005798 (450)\ttotal: 2m 43s\tremaining: 17.7s\n",
      "499:\ttest: 0.8008790\tbest: 0.8009219 (489)\ttotal: 3m\tremaining: 0us\n",
      "\n",
      "bestTest = 0.8009218906\n",
      "bestIteration = 489\n",
      "\n",
      "Shrink model to first 490 iterations.\n",
      "VALID AUC : 0.8009218906137493 ACC : 0.726457399103139\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {'iterations': 500, 'depth': 8, 'learning_rate': 0.05, 'eval_metric': 'AUC'}\n",
    "model = cbt(**params)\n",
    "model.fit(data_train, eval_set=data_test, verbose=50)\n",
    "\n",
    "\n",
    "preds = model.predict(test[FEATS])\n",
    "acc = accuracy_score(y_test, np.where(preds >= 0.5, 1, 0))\n",
    "auc = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(f'VALID AUC : {auc} ACC : {acc}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance:\n",
      "KnowledgeTag: 1.1678089120795294\n",
      "Dffclt: 32.43888138112129\n",
      "Dscrmn: 4.626252971956579\n",
      "Gussng: 6.696824402388\n",
      "testTag: 5.77825932499787\n",
      "user_correct_answer: 1.2169726555491673\n",
      "user_total_answer: 0.668994063488848\n",
      "user_acc: 3.580148620004684\n",
      "user_mean: 2.472197760939635\n",
      "relative_answer_mean: 13.606148962335576\n",
      "time_to_solve: 15.515624394494708\n",
      "time_to_solve_mean: 10.286859771111818\n",
      "prior_testTag_frequency: 1.9450267795322005\n"
     ]
    }
   ],
   "source": [
    "feature_importance = model.get_feature_importance()\n",
    "print(\"Feature Importance:\")\n",
    "for i, importance in zip(FEATS, feature_importance):\n",
    "    print(f\"{i}: {importance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_369617/4246852483.py:61: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df['time_to_solve'].fillna(method='ffill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# LOAD TESTDATA\n",
    "test_csv_file_path = os.path.join(data_dir, 'test_data_3PL+level.csv')\n",
    "test_df = pd.read_csv(test_csv_file_path)\n",
    "#test_df = test_df.drop(['user_level'], axis=1)\n",
    "\n",
    "# FEATURE ENGINEERING\n",
    "test_df = feature_engineering(test_df)\n",
    "\n",
    "# LEAVE LAST INTERACTION ONLY\n",
    "test_df = test_df[test_df['userID'] != test_df['userID'].shift(-1)]\n",
    "\n",
    "# DROP ANSWERCODE\n",
    "test_df = test_df.drop(['answerCode'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE PREDICTION\n",
    "total_preds = model.predict(test_df[FEATS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing prediction : ./output/submission_CatReg_FE.csv\n"
     ]
    }
   ],
   "source": [
    "# SAVE OUTPUT\n",
    "output_dir = './output/'\n",
    "write_path = os.path.join(output_dir, \"submission_CatReg_FE.csv\")\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "with open(write_path, 'w', encoding='utf8') as w:\n",
    "    print(\"writing prediction : {}\".format(write_path))\n",
    "    w.write(\"id,prediction\\n\")\n",
    "    for id, p in enumerate(total_preds):\n",
    "        w.write('{},{}\\n'.format(id,p))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dkt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
