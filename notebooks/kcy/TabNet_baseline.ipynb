{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TabNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/tabular/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pytorch_tabnet.tab_model import TabNetRegressor, TabNetClassifier\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 로드"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seeds(seed: int = 42):\n",
    "    # 랜덤 시드를 설정하여 매 코드를 실행할 때마다 동일한 결과를 얻게 합니다.\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "set_seeds(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data/'\n",
    "train_data_path = os.path.join(data_dir, 'train_data_3PL+level.csv')\n",
    "test_data_path = os.path.join(data_dir, 'test_data_3PL+level.csv') \n",
    "df = pd.read_csv(train_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "\n",
    "    # 유저별로 정렬\n",
    "    df.sort_values(by=['userID', 'Timestamp'], inplace=True)\n",
    "    \n",
    "    # 데이터 타입 변경\n",
    "    dtype = {\n",
    "        'userID': 'int16',\n",
    "        'answerCode': 'int8',\n",
    "        'KnowledgeTag': 'int16'\n",
    "    }\n",
    "    df = df.astype(dtype)\n",
    "    \n",
    "    # 'Timestamp' 열을 날짜/시간 형식으로 파싱\n",
    "    df['Timestamp'] = pd.to_datetime(df['Timestamp'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    # testTag 추가\n",
    "    df['testTag'] = df['testId'].apply(lambda x: x[2]).astype('int16')\n",
    "\n",
    "    # 유저별로 정답 누적 횟수 계산, 결측치 0\n",
    "    df['user_correct_answer'] = df.groupby('userID')['answerCode'].transform(lambda x: x.cumsum().shift(1))\n",
    "    df['user_correct_answer'].fillna(0, inplace=True)\n",
    "    \n",
    "    # 유저별로 제출 누적 횟수 계산\n",
    "    df['user_total_answer'] = df.groupby('userID')['answerCode'].cumcount() \n",
    "    \n",
    "    # 유저별로 누적 정답률 계산, 결측치 0.75\n",
    "    df['user_acc'] = df['user_correct_answer'] / df['user_total_answer']\n",
    "    df['user_acc'].fillna(0.75, inplace=True)\n",
    "\n",
    "    # userID별 정답률 추가\n",
    "    df['user_sum'] = df.groupby('userID')['answerCode'].transform('sum')\n",
    "    df['user_mean'] = df.groupby('userID')['answerCode'].transform('mean')\n",
    "    \n",
    "    # assessmentItemID별 정답률 추가\n",
    "    df['assessment_sum'] = df.groupby('assessmentItemID')['answerCode'].transform('sum')\n",
    "    df['assessment_mean'] = df.groupby('assessmentItemID')['answerCode'].transform('mean')\n",
    "    \n",
    "    # testId별 정답률 추가\n",
    "    df['test_sum'] = df.groupby('testId')['answerCode'].transform('sum')\n",
    "    df['test_mean'] = df.groupby('testId')['answerCode'].transform('mean')\n",
    "    \n",
    "    # KnowledgeTag별 정답률 추가\n",
    "    df['knowledgeTag_sum'] = df.groupby('KnowledgeTag')['answerCode'].transform('sum')\n",
    "    df['knowledgeTag_mean'] = df.groupby('KnowledgeTag')['answerCode'].transform('mean')\n",
    "    \n",
    "    # testTag별 정답률 추가\n",
    "    df['testTag_sum'] = df.groupby('testTag')['answerCode'].transform('sum')\n",
    "    df['testTag_mean'] = df.groupby('testTag')['answerCode'].transform('mean')\n",
    "\n",
    "    # 상대적 정답률\n",
    "    df['relative_answer_assessment'] = df['answerCode'] - df.groupby('assessmentItemID')['answerCode'].transform('mean')\n",
    "    \n",
    "    # 유저별 상대적 정답률 평균 - 학습 수준 레벨\n",
    "    df['relative_answer_mean'] = df.groupby('userID')['relative_answer_assessment'].transform('mean')\n",
    "\n",
    "    # 유저가 문항을 푼 시간\n",
    "    df['time_to_solve'] = df.groupby(['userID', 'testId'])['Timestamp'].diff().dt.total_seconds().shift(-1)\n",
    "    \n",
    "    # 결측치 이전 행의 값으로 채움\n",
    "    df['time_to_solve'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "    # 유저별 문항 시간 평균\n",
    "    #df['time_to_solve_mean'] = df.groupby('userID')['time_to_solve'].transform('mean')\n",
    "    df['time_to_solve_mean'] = df.groupby(['userID', 'testId'])['time_to_solve'].transform('mean')\n",
    "\n",
    "    # clip(0, 255)는 메모리를 위해 uint8 데이터 타입을 쓰기 위함\n",
    "    df['prior_assessment_frequency'] = df.groupby(['userID', 'assessmentItemID']).cumcount().clip(0, 255)\n",
    "\n",
    "    # 각 태그별로 이전에 몇번 풀었는지\n",
    "    df['prior_KnowledgeTag_frequency'] = df.groupby(['userID', 'KnowledgeTag']).cumcount()\n",
    "    \n",
    "    # 시험지 태그별 학년별 몇번 풀었는지\n",
    "    df['prior_testTag_frequency'] = df.groupby(['userID', 'testTag']).cumcount()\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_123755/165607907.py:61: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df['time_to_solve'].fillna(method='ffill', inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>assessmentItemID</th>\n",
       "      <th>testId</th>\n",
       "      <th>answerCode</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>KnowledgeTag</th>\n",
       "      <th>Dffclt</th>\n",
       "      <th>Dscrmn</th>\n",
       "      <th>Gussng</th>\n",
       "      <th>user_level</th>\n",
       "      <th>...</th>\n",
       "      <th>knowledgeTag_mean</th>\n",
       "      <th>testTag_sum</th>\n",
       "      <th>testTag_mean</th>\n",
       "      <th>relative_answer_assessment</th>\n",
       "      <th>relative_answer_mean</th>\n",
       "      <th>time_to_solve</th>\n",
       "      <th>time_to_solve_mean</th>\n",
       "      <th>prior_assessment_frequency</th>\n",
       "      <th>prior_KnowledgeTag_frequency</th>\n",
       "      <th>prior_testTag_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A060001001</td>\n",
       "      <td>A060000001</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-03-24 00:17:11</td>\n",
       "      <td>7224</td>\n",
       "      <td>-2.017182</td>\n",
       "      <td>20.079513</td>\n",
       "      <td>0.052178</td>\n",
       "      <td>0.015996</td>\n",
       "      <td>...</td>\n",
       "      <td>0.955022</td>\n",
       "      <td>187545</td>\n",
       "      <td>0.709232</td>\n",
       "      <td>0.017937</td>\n",
       "      <td>-0.025899</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.833333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>A060001002</td>\n",
       "      <td>A060000001</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-03-24 00:17:14</td>\n",
       "      <td>7225</td>\n",
       "      <td>-1.723821</td>\n",
       "      <td>4.616495</td>\n",
       "      <td>0.056888</td>\n",
       "      <td>0.015996</td>\n",
       "      <td>...</td>\n",
       "      <td>0.913187</td>\n",
       "      <td>187545</td>\n",
       "      <td>0.709232</td>\n",
       "      <td>0.035874</td>\n",
       "      <td>-0.025899</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.833333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>A060001003</td>\n",
       "      <td>A060000001</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-03-24 00:17:22</td>\n",
       "      <td>7225</td>\n",
       "      <td>-0.167255</td>\n",
       "      <td>18.583456</td>\n",
       "      <td>0.754422</td>\n",
       "      <td>0.015996</td>\n",
       "      <td>...</td>\n",
       "      <td>0.913187</td>\n",
       "      <td>187545</td>\n",
       "      <td>0.709232</td>\n",
       "      <td>0.089686</td>\n",
       "      <td>-0.025899</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.833333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>A060001004</td>\n",
       "      <td>A060000001</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-03-24 00:17:29</td>\n",
       "      <td>7225</td>\n",
       "      <td>0.496282</td>\n",
       "      <td>39.877030</td>\n",
       "      <td>0.946875</td>\n",
       "      <td>0.015996</td>\n",
       "      <td>...</td>\n",
       "      <td>0.913187</td>\n",
       "      <td>187545</td>\n",
       "      <td>0.709232</td>\n",
       "      <td>0.031390</td>\n",
       "      <td>-0.025899</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.833333</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>A060001005</td>\n",
       "      <td>A060000001</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-03-24 00:17:36</td>\n",
       "      <td>7225</td>\n",
       "      <td>-1.335100</td>\n",
       "      <td>6.965071</td>\n",
       "      <td>0.237969</td>\n",
       "      <td>0.015996</td>\n",
       "      <td>...</td>\n",
       "      <td>0.913187</td>\n",
       "      <td>187545</td>\n",
       "      <td>0.709232</td>\n",
       "      <td>0.058296</td>\n",
       "      <td>-0.025899</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.833333</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID assessmentItemID      testId  answerCode           Timestamp  \\\n",
       "0       0       A060001001  A060000001           1 2020-03-24 00:17:11   \n",
       "1       0       A060001002  A060000001           1 2020-03-24 00:17:14   \n",
       "2       0       A060001003  A060000001           1 2020-03-24 00:17:22   \n",
       "3       0       A060001004  A060000001           1 2020-03-24 00:17:29   \n",
       "4       0       A060001005  A060000001           1 2020-03-24 00:17:36   \n",
       "\n",
       "   KnowledgeTag    Dffclt     Dscrmn    Gussng  user_level  ...  \\\n",
       "0          7224 -2.017182  20.079513  0.052178    0.015996  ...   \n",
       "1          7225 -1.723821   4.616495  0.056888    0.015996  ...   \n",
       "2          7225 -0.167255  18.583456  0.754422    0.015996  ...   \n",
       "3          7225  0.496282  39.877030  0.946875    0.015996  ...   \n",
       "4          7225 -1.335100   6.965071  0.237969    0.015996  ...   \n",
       "\n",
       "   knowledgeTag_mean  testTag_sum  testTag_mean  relative_answer_assessment  \\\n",
       "0           0.955022       187545      0.709232                    0.017937   \n",
       "1           0.913187       187545      0.709232                    0.035874   \n",
       "2           0.913187       187545      0.709232                    0.089686   \n",
       "3           0.913187       187545      0.709232                    0.031390   \n",
       "4           0.913187       187545      0.709232                    0.058296   \n",
       "\n",
       "   relative_answer_mean  time_to_solve  time_to_solve_mean  \\\n",
       "0             -0.025899            3.0            7.833333   \n",
       "1             -0.025899            8.0            7.833333   \n",
       "2             -0.025899            7.0            7.833333   \n",
       "3             -0.025899            7.0            7.833333   \n",
       "4             -0.025899           11.0            7.833333   \n",
       "\n",
       "   prior_assessment_frequency  prior_KnowledgeTag_frequency  \\\n",
       "0                           0                             0   \n",
       "1                           0                             0   \n",
       "2                           0                             1   \n",
       "3                           0                             2   \n",
       "4                           0                             3   \n",
       "\n",
       "   prior_testTag_frequency  \n",
       "0                        0  \n",
       "1                        1  \n",
       "2                        2  \n",
       "3                        3  \n",
       "4                        4  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = feature_engineering(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train/Test 데이터 셋 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_split_and_encoding(df, feats, cat_feats, ratio=0.7):\n",
    "    \n",
    "    for col in cat_feats:\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col].values)\n",
    "    \n",
    "    users = list(zip(df['userID'].value_counts().index, df['userID'].value_counts()))\n",
    "    random.shuffle(users)\n",
    "\n",
    "    max_train_data_len = ratio*len(df)\n",
    "    sum_of_train_data = 0\n",
    "    user_ids =[]\n",
    "\n",
    "    for user_id, count in users:\n",
    "        sum_of_train_data += count\n",
    "        if max_train_data_len < sum_of_train_data:\n",
    "            break\n",
    "        user_ids.append(user_id)\n",
    "    \n",
    "    train = df[df['userID'].isin(user_ids)][feats]\n",
    "    valid = df[df['userID'].isin(user_ids) == False][feats]\n",
    "    \n",
    "    valid = valid[valid['userID'] != valid['userID'].shift(-1)]\n",
    "\n",
    "    cat_idxs = [ i for i, f in enumerate(feats) if f in cat_feats]\n",
    "    cat_dims = [ len(df[f].unique()) for f in feats if f in cat_feats]\n",
    "    \n",
    "    return train, valid, cat_idxs, cat_dims\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATS = [\n",
    "    'userID', 'assessmentItemID', 'testId', \n",
    "    'KnowledgeTag',\n",
    "    'Dffclt',\n",
    "    'Dscrmn',\n",
    "    'Gussng',\n",
    "    # 'testTag',\n",
    "    'user_correct_answer',\n",
    "    'user_total_answer',\n",
    "    'user_acc',\n",
    "    'user_mean',\n",
    "    'relative_answer_mean',\n",
    "    'time_to_solve',\n",
    "    'time_to_solve_mean',\n",
    "    'prior_testTag_frequency',\n",
    "    'answerCode'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['userID', 'assessmentItemID', 'testId', 'KnowledgeTag']\n",
    "train, valid, cat_idxs, cat_dims = custom_split_and_encoding(df, cat_feats=cat_cols, feats=FEATS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(['answerCode'], axis = 1)\n",
    "y_train = train[['answerCode']]\n",
    "X_valid = valid.drop(['answerCode'], axis = 1)\n",
    "y_valid = valid[['answerCode']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 훈련 및 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 0.53224 | train_auc: 0.79517 | train_accuracy: 0.75078 | train_logloss: 0.51365 | valid_auc: 0.75453 | valid_accuracy: 0.69258 | valid_logloss: 0.59191 |  0:01:50s\n",
      "epoch 1  | loss: 0.51526 | train_auc: 0.79662 | train_accuracy: 0.75114 | train_logloss: 0.51287 | valid_auc: 0.75374 | valid_accuracy: 0.68859 | valid_logloss: 0.59038 |  0:03:44s\n",
      "Stop training because you reached max_epochs = 2 with best_epoch = 1 and best_valid_logloss = 0.59038\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    }
   ],
   "source": [
    "model = TabNetClassifier(\n",
    "    n_d = 64,\n",
    "    n_a = 64,\n",
    "    cat_idxs=cat_idxs,\n",
    "    cat_dims=cat_dims,\n",
    "    cat_emb_dim=10,\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=1e-2),\n",
    "    scheduler_params={\"step_size\":50,\n",
    "                        \"gamma\":0.9},\n",
    "    scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "    mask_type='sparsemax', # \"sparsemax\", entmax\n",
    "    verbose=1,\n",
    "    device_name='cuda'\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train=X_train.values, y_train=y_train.values.flatten(),\n",
    "    eval_set=[(X_train.values, y_train.values.flatten()), (X_valid.values, y_valid.values.flatten())],\n",
    "    eval_name=['train', 'valid'],\n",
    "    eval_metric=['auc', 'accuracy', 'logloss'],\n",
    "    max_epochs=2,\n",
    "    patience=5,\n",
    "    batch_size=1024,\n",
    "    virtual_batch_size=128,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict_proba(X_valid.values)\n",
    "preds_proba = np.max(result, axis=1)\n",
    "preds = np.argmax(result, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID AUC : 0.49783641423176306 ACC : 0.6885899352267065\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(y_valid, preds)\n",
    "auc = roc_auc_score(y_valid, preds_proba)\n",
    "print(f'VALID AUC : {auc} ACC : {acc}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_123755/165607907.py:61: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df['time_to_solve'].fillna(method='ffill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(test_data_path)\n",
    "\n",
    "test_df = feature_engineering(test_df)\n",
    "\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    test_df[col] = le.fit_transform(test_df[col].values)\n",
    "\n",
    "# y_test = test_df['answerCode'].values\n",
    "# X_test = test_df.drop(['answerCode'], axis=1)\n",
    "\n",
    "# #FEATS = [col for col in X_test.columns]\n",
    "# X_text = X_test[FEATS]\n",
    "test_df = test_df[FEATS]\n",
    "test_df = test_df[test_df['userID'] != test_df['userID'].shift(-1)]\n",
    "\n",
    "# DROP ANSWERCODE\n",
    "test_df = test_df.drop(['answerCode'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE PREDICTION\n",
    "total_preds = model.predict_proba(test_df.values)\n",
    "total_preds = np.max(result, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing prediction : output/submission.csv\n"
     ]
    }
   ],
   "source": [
    "output_dir = 'output/'\n",
    "write_path = os.path.join(output_dir, \"submission.csv\")\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "with open(write_path, 'w', encoding='utf8') as w:\n",
    "    print(\"writing prediction : {}\".format(write_path))\n",
    "    w.write(\"id,prediction\\n\")\n",
    "    for id, p in enumerate(total_preds):\n",
    "        w.write('{},{}\\n'.format(id,p))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tabular",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
